import settings
import uvicorn
from fastapi import FastAPI, UploadFile, File, HTTPException
from transformers import WhisperForConditionalGeneration, WhisperProcessor, pipeline
import torch
import tempfile
import time
from pydub import AudioSegment
import os
import numpy as np
# --- –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–∏ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ NumPy ---
from scipy.io.wavfile import write as write_wav
import logging # –î–ª—è –ª—É—á—à–µ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
# ---------------------------------------------

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


app = FastAPI()

# –†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
ALLOWED_EXTENSIONS = {".wav", ".oga", ".mp3", ".flac", ".m4a"}
MAX_FILE_SIZE_MB = 256

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
MODEL_NAME = "openai/whisper-large-v3" # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
TORCH_DTYPE = torch.float32

logger.info("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä...")
try:
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ä–∞–∑—É –Ω–∞ CPU
    model = WhisperForConditionalGeneration.from_pretrained(
        MODEL_NAME,
        torch_dtype=TORCH_DTYPE,
        low_cpu_mem_usage=True,
        use_safetensors=True
    ).to("cpu") # –Ø–≤–Ω–æ –Ω–∞ CPU –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ

    processor = WhisperProcessor.from_pretrained(MODEL_NAME)
    logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≥–æ—Ç–æ–≤—ã.")
except Exception as e:
    logger.exception("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä!")
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É –∏–ª–∏ –ø–µ—Ä–µ–π—Ç–∏ –≤ –∞–≤–∞—Ä–∏–π–Ω—ã–π —Ä–µ–∂–∏–º
    model = None
    processor = None

# --- –ü–∞–π–ø–ª–∞–π–Ω –ª—É—á—à–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–æ–∑–∂–µ, –∫–æ–≥–¥–∞ –∏–∑–≤–µ—Å—Ç–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ---

def is_gpu_available(threshold_mb: int = 10000) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏ –Ω–∞ GPU."""
    if model is None: # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å, GPU –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ –±—É–¥–µ–º
        return False
    if torch.cuda.is_available():
        try:
            free_mem, total_mem = torch.cuda.mem_get_info()
            free_mem_mb = free_mem / (1024 ** 2)
            logger.info(f"‚ÑπÔ∏è –î–æ—Å—Ç—É–ø–Ω–æ –ø–∞–º—è—Ç–∏ GPU: {free_mem_mb:.2f} MB")
            return free_mem_mb > threshold_mb
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø–∞–º—è—Ç–∏ GPU: {e}")
            return False
    return False


@app.post("/transcribe/")
async def transcribe(file: UploadFile = File(...)):
    # --- –Ø–í–ù–û –£–ö–ê–ó–´–í–ê–ï–ú –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –ì–õ–û–ë–ê–õ–¨–ù–´–• –ü–ï–†–ï–ú–ï–ù–ù–´–• ---
    global model, processor
    # --------------------------------------------------------

    if model is None or processor is None:
         raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞).")

    tmp_input_path = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª—è finally
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        ext = os.path.splitext(file.filename)[-1].lower()
        if ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(status_code=400, detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {ext}")

        contents = await file.read()
        size_mb = len(contents) / (1024 * 1024)
        logger.info(f"–ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª: {file.filename}, –†–∞–∑–º–µ—Ä: {size_mb:.2f} MB, –¢–∏–ø: {file.content_type}")

        # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ñ–∞–π–ª ---
        debug_dir = "debug_audio"
        os.makedirs(debug_dir, exist_ok=True)
        debug_filename = os.path.join(debug_dir, f"received_{time.time()}_{file.filename}")
        try:
            with open(debug_filename, "wb") as df:
                df.write(contents)
            logger.info(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏: {debug_filename}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π —Ñ–∞–π–ª: {e}")
        # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò ---

        if size_mb > MAX_FILE_SIZE_MB:
            raise HTTPException(status_code=413, detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({size_mb:.2f} –ú–ë). –ú–∞–∫—Å–∏–º—É–º ‚Äî {MAX_FILE_SIZE_MB} –ú–ë") # 413 Payload Too Large

        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp_input:
            tmp_input.write(contents)
            tmp_input_path = tmp_input.name
            logger.info(f"üìÑ –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {tmp_input_path}")

        samples = None
        duration_sec = 0
        # --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ ---
        try:
            logger.info(f"üéß –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ: {tmp_input_path}")
            audio = AudioSegment.from_file(tmp_input_path)
            duration_sec = len(audio) / 1000.0

            audio = audio.set_frame_rate(16000).set_channels(1)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ float32 [-1, 1]
            samples = np.array(audio.get_array_of_samples()).astype(np.float32)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º sample_width –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            if audio.sample_width == 2: # 16 –±–∏—Ç
                samples /= 32768.0
            elif audio.sample_width == 4: # 32 –±–∏—Ç–∞
                 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è float32 –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∏–∑ int32
                samples /= 2147483648.0
            elif audio.sample_width == 1: # 8 –±–∏—Ç
                 samples /= 128.0 # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 0
            else:
                 logger.warning(f"–ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —à–∏—Ä–∏–Ω–∞ —Å—ç–º–ø–ª–∞: {audio.sample_width}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—â–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è.")
                 # –û–±—â–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω–æ–π
                 samples /= np.iinfo(f'int{audio.sample_width * 8}').max

            samples = np.clip(samples, -1.0, 1.0) # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ

            logger.info(f"‚úÖ –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å {duration_sec:.2f} —Å–µ–∫, shape={samples.shape}, dtype={samples.dtype}")

            # --- –û–¢–õ–ê–î–ö–ê: –°–æ—Ö—Ä–∞–Ω—è–µ–º NumPy –º–∞—Å—Å–∏–≤ –∫–∞–∫ WAV ---
            debug_numpy_filename = os.path.join(debug_dir, f"numpy_{time.time()}_{file.filename}.wav")
            try:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ int16 –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π WAV
                samples_int16 = np.clip(samples * 32767, -32768, 32767).astype(np.int16)
                write_wav(debug_numpy_filename, 16000, samples_int16) # 16000 Hz
                logger.info(f"üìù NumPy –º–∞—Å—Å–∏–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏: {debug_numpy_filename}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π NumPy WAV: {e}")
            # --- –ö–û–ù–ï–¶ –û–¢–õ–ê–î–ö–ò ---

        except Exception as e:
            logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ {file.filename} —Å –ø–æ–º–æ—â—å—é pydub: {e}")
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {e}")
        # --- –ö–æ–Ω–µ—Ü –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ ---

        if samples is None:
             raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ.")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device_used = "cpu"
        current_device = torch.device("cpu")
        dtype_used = TORCH_DTYPE
        model_on_gpu = False # –§–ª–∞–≥, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–º–µ—â–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ

        if is_gpu_available():
            logger.info("üöÄ –û–±–Ω–∞—Ä—É–∂–µ–Ω GPU —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –ø–∞–º—è—Ç—å—é. –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU...")
            try:
                model.to("cuda") # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
                current_device = torch.device("cuda")
                device_used = "cuda"
                model_on_gpu = True
                # dtype_used = torch.float16 # –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º float16 –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ GPU.")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ GPU: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU.")
                # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å —Ç–æ—á–Ω–æ –Ω–∞ CPU, –µ—Å–ª–∏ –æ–Ω–∞ —É–∂–µ —Ç–∞–º - –æ—à–∏–±–∫–∏ –Ω–µ –±—É–¥–µ—Ç
                model.to("cpu") # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
                current_device = torch.device("cpu")
                device_used = "cpu"
                dtype_used = TORCH_DTYPE
                model_on_gpu = False
        else:
            logger.info("‚ÑπÔ∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏. –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU.")
            model.to("cpu") # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
            current_device = torch.device("cpu")
            device_used = "cpu"
            model_on_gpu = False


        # ‚öôÔ∏è –°–æ–∑–¥–∞—ë–º pipeline
        logger.info(f"‚öôÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: {device_used}")
        asr_pipeline_local = pipeline(
            "automatic-speech-recognition",
            model=model,
            tokenizer=processor.tokenizer,
            feature_extractor=processor.feature_extractor,
            chunk_length_s=30,
            return_timestamps=True,
            device=current_device,
            torch_dtype=dtype_used
        )
        logger.info(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω —Å–æ–∑–¥–∞–Ω –¥–ª—è {device_used}.")

        # üïí –í—Ä–µ–º—è –∏ –∑–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        start_time = time.time()
        logger.info("üé§ –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è...")

        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–Ω–∏–∑–∏—Ç—å –ø–æ—Ä–æ–≥ VAD
        generate_kwargs = {"no_speech_threshold": 0.5} # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–µ–º

        result = asr_pipeline_local(samples.copy())
        elapsed = time.time() - start_time

        logger.info(f"‚è±Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {elapsed:.2f} —Å–µ–∫ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device_used}")
        logger.info(f"üéß –ü–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}") # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç

        # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —á–∞–Ω–∫–æ–≤ (—Ç–∞–∫ –∫–∞–∫ return_timestamps='word')
        final_text = " ".join([chunk['text'] for chunk in result.get("chunks", [])]).strip()

        logger.info(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç (—Ç–µ–∫—Å—Ç): {final_text[:200]}...")

        return {
                "filename": file.filename,
                "format": ext,
                "duration_seconds": duration_sec,
                "text": final_text, # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                "device": device_used,
                "inference_time": elapsed,
                "full_result": result # –ú–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –Ω–∞ –∫–ª–∏–µ–Ω—Ç–µ
            }

    except HTTPException as e:
        # –õ–æ–≥–∏—Ä—É–µ–º HTTP –∏—Å–∫–ª—é—á–µ–Ω–∏—è —Ç–æ–∂–µ
        logger.error(f"HTTP –æ—à–∏–±–∫–∞: {e.status_code} - {e.detail}")
        raise e
    except Exception as e:
        logger.exception(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {file.filename}: {e}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")
    finally:
        # üîÅ –ü–µ—Ä–µ–≤–æ–¥ –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ CPU, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–∞–ª–∞—Å—å –Ω–∞ GPU
        if model_on_gpu:
            try:
                logger.info("üîÅ –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ CPU...")
                model.to("cpu")
                torch.cuda.empty_cache()
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞ CPU, –∫—ç—à GPU –æ—á–∏—â–µ–Ω.")
            except Exception as e:
                 logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ CPU –∏–ª–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞: {e}")

        # --- –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ ---
        if tmp_input_path and os.path.exists(tmp_input_path):
            try:
                os.remove(tmp_input_path)
                logger.info(f"üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω: {tmp_input_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {tmp_input_path}: {e}")


if __name__ == "__main__":
    port = getattr(settings, 'api_port', 8000)
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    # –ó–∞–ø—É—Å–∫–∞–µ–º —á–µ—Ä–µ–∑ uvicorn –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ async
    # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ reload=True —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
    uvicorn.run("your_module_name:app", host="0.0.0.0", port=port, reload=False)
    # –ó–∞–º–µ–Ω–∏—Ç–µ "your_module_name" –Ω–∞ –∏–º—è –≤–∞—à–µ–≥–æ Python —Ñ–∞–π–ª–∞ (–±–µ–∑ .py)